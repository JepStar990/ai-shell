import typer
import subprocess
from typing import Optional
from adapters import OpenAIAdapter
#from adapters import GeminiAdapter
from services import ContextService, PromptService
from rich.console import Console
from rich.prompt import Confirm
from config import config

app = typer.Typer()
console = Console()
context_service = ContextService()
prompt_service = PromptService()

def execute_command(command: str, confirm: bool = True) -> bool:
    """Handle actual command execution with proper error handling"""
    if not command:
        console.print("[red]Error: No command generated[/red]")
        return False
        
    if confirm:
        if not Confirm.ask(f"Execute: [bold green]{command}[/]?"):
            console.print("[yellow]Aborted[/yellow]")
            return False
            
    try:
        console.print(f"[bold]Executing:[/bold] [cyan]{command}[/cyan]")
        
        # Actual execution with proper streaming output
        process = subprocess.Popen(
            command,
            shell=True,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True
        )
        
        # Stream output in real-time
        for line in process.stdout:
            console.print(line, end='')
            
        process.wait()
        
        if process.returncode != 0:
            console.print(f"[red]Error: Command failed with exit code {process.returncode}[/red]")
            console.print(f"[red]Error output:[/red]\n{process.stderr.read()}")
            return False
            
        console.print("[green]âœ“ Command executed successfully[/green]")
        return True
        
    except Exception as e:
        console.print(f"[red]Error executing command: {str(e)}[/red]")
        return False

@app.command()
def ask(
    prompt: Optional[str] = typer.Argument(None, help="Your command prompt"),
    model: Optional[str] = None,
    temperature: float = 0.3,
    max_tokens: int = 2000,
    yes: bool = False,
    verbose: bool = False,
    p: Optional[str] = typer.Option(None, "--prompt", "-p", help="Your command prompt")
):
    """AI-powered shell command generator"""
    # Determine which prompt to use
    full_prompt = prompt or p
    if not full_prompt:
        typer.echo("Error: No prompt provided")
        raise typer.Exit(1)

    """AI-powered shell command generator"""
    # Combine all prompt parts into a single string
    full_prompt = " ".join(prompt)
    
    try:
        # Initialize services
        adapter = OpenAIAdapter(
            model=model or config.DEFAULT_MODEL,
            temperature=temperature,
            max_tokens=max_tokens
        )

        # Gather context
        if verbose:
            console.print("[dim]Gathering system context...[/dim]")
        context = context_service.gather()
        
        # Build prompt
        if verbose:
            console.print("[dim]Constructing optimized prompt...[/dim]")
        full_prompt = prompt_service.build_prompt(prompt, context)
        
        if verbose:
            console.print("\n[blue]Full Prompt Being Sent:[/blue]")
            console.print(full_prompt)
            console.print("\n[dim]Querying AI...[/dim]")
        
        # Get response
        response = adapter.query(full_prompt)
        
        # Process response
        console.print(f"\n[bold]AI Suggests:[/bold]\n[cyan]{response}[/cyan]")
        execute_command(response, confirm=not yes)
        
    except Exception as e:
        console.print(f"[red]Error: {str(e)}[/red]")
        raise typer.Exit(1)

if __name__ == "__main__":
    app()
